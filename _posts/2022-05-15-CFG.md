---
layout: post
title: Context Free Grammar
summary: 本篇文章主要讲解了前馈神经网络在NLP中的应用，包括基于前馈神经网络的主题分类(Top Classification)，基于前馈神经网络的语言模型(FFNN-LM)以及基于前馈神经网络的POS Tagging.
featured-img: deep learning
language: chinese
category: NLP
---

![image-1](/assets/img/post_img/CFG.png)

# Context Free Grammar

对于那些不能用regular expressions来捕捉的句子，可以使用context free grammar

## 1. Basics of Context-Free Grammars

### 1.1 Symbols

- **Terminal symbols**: *rat, the, ate, cheese* 
- **Non-terminal symbols**: S, NP, VP, DT, VBD, NN 

### 1.2 Productions (rules)

#### 1.2.1 **Key Constituents in Penn Treebank**

• Sentence (S) 

• Noun phrase (NP) 

• Verb phrase (VP) 

• Prepositional phrase (PP) 

• Adjective phrase (AdjP) 

• Adverbial phrase (AdvP) 

• Subordinate clause (SBAR)

#### 1.2.2 **Basic English Sentence Structures**

• Declarative sentences陈述句 (S → NP VP) 

‣ *The rat ate the cheese* 

• Imperative sentences祈使句 (S → VP) 

‣ *Eat the cheese!* 

• Yes/no questions (S → VB NP VP) 

‣ *Did the rat eat the cheese?* 

• *Wh-*subject-questions (S → WH VP)

‣ *Who ate the cheese?* 

• *Wh*-object-questions (S → WH VB NP VP)

‣ *What did the rat eat?*

#### 1.2.3 **Other Constituents**

• Prepositional phrase 介词短语 

‣ PP → IN NP *in the house*

• Adjective phrase 副词短语

‣ AdjP → (AdvP) JJ *really nice*

• Adverb phrase 动词短语

‣ AdvP → (AdvP) RB *not too well*

• Subordinate clause 从句 

‣ SBAR → (IN) S *since I came here*

• Coordination 

‣ NP → NP CC NP; VP → VP CC VP; etc. *Jack and Jill*

• Complex sentences 

‣ S → S SBAR; S → SBAR S; etc. *if he goes, I’ll go*

## 2. CFG Parsing

- judge一个sentence是否是grammatical的
- cover most **syntactic patterns**
- computational efficient
- use CFG to describe English syntax的核心fragment

给定一个Production rules

- $$S\rightarrow a S b$$
- $$S\rightarrow ab$$

和一个String: **aaabbb**

可以得到CFG Parse tree

![image1](/assets/img/post_img/100.png)


### 2.1 Generate Sentences with CFGs

- Start with start symbol **S**
- Apply a rule with **S** on **LHS** (S$$\rightarrow$$ NP VP)
  - NP VP
- Apply a rule with **NP** on **LHS  **(NP$$\rightarrow$$ DT NN)
  - DT NN VP
- Apply a rule with **DT** on **LHS** (DT$$\rightarrow$$ the)
  - the NN VP
- Apply rule with **NN** on **LHS** (NN$$\rightarrow$$ rat)
  - the rat VP
- Apply rule with **VP** on **LHS** (VP$$\rightarrow$$ VBD NP)
  - the rat VBD NP
- Apply rule with **DT** on **LHS** (DT $$\rightarrow$$ *the*) 
  - the rat ate the NN
- Apply rule with **NN** on **LHS** (NN $$\rightarrow$$ *cheese*)
  - **the rat ate the cheese**
  - 当没有non-terminals了，就说明结束了

## 3. Constituents

### 3.1 Syntactic Constituents

- sentences被分为constituents

- helps build CFG production rules

### 3.2 Key properties

#### 3.2.1 可移动（movement）

- constituents可以在sentences中移动

- e.g.,

  -  Abigail gave [her brother] [a fish] 

  -  Abigail gave [a fish] to [her brother]

#### 3.2.2 可替换（substitution）

- constituents可以被其他相同type的phrases替换
- e.g.,
  - Max thanked [his older sister] 
  - Max thanked [her]

#### 3.2.3 coordination

- constituents可以和一些连词and | or联合使用

- e.g., 

  - [Abigail] and [her young brother] brought a fish 

    Abigail [bought a fish] and [gave it to Max] 

    Abigail [bought] and [greedily ate] a fish

## 4. CYK Algorithm

- bottom-up parsing
- 根据给定的CFG测试一个string是否是valid的，不enumerating所有可能的parses。

- core idea: 从下往上，form small constituents -> merge them into large constituents
- Requirement: CFGs 必须是Chomsky Normal Forms

### 4.1 Chomsky Normal Forms （CNF）

- 所有rules形如: $$A\rightarrow BC, A\rightarrow a$$
- 将rules $$A\rightarrow B c$$转为：
  - $$A\rightarrow BX, X\rightarrow c$$
- 将rules $$A\rightarrow BCD$$转为
  - $$A\rightarrow BY, Y\rightarrow CD$$
- CNF不允许**unary rules**（$$A\rightarrow B$$）
  - 假设可以有NP -> S 且S -> NP那么tree很多时候会infinite

### 4.2 The CYK Parsing Algorithm

- convert grammer to CNF

- fill in a parse table (**left to right, bottom to top**)

- Use table to derive parse

- S in top right corner of table == succuess!

- convert result back to original grammer

![image101](/assets/img/post_img/101.png)

## 5. Probability  CFG

### 5.1 Problems of CFG

- Poor independence assumptions
  - solution: parent conditioning
- lack of lexical conditioning
  - solution: head lexicalization

由于CFG tree可以有多个，于是我们引入product的probability

一颗树的probability $$P(tree)=\prod_i P(rule_i)$$

![image1](/assets/img/post_img/102.png)