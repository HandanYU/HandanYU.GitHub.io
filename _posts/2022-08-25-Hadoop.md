---
layout: post
title: Hadoop
summary: 本章讲述了Hadoop的运行机制
featured-img: machine learning
language: chinese 
category: Big Data
---
# hadoop特性
- 支持多种编程语言
- 高可靠性
- 高容错性

# 搭建hadoop集群的3个xml文件
## core-site.xml
核心配置文件，可以通过调整里面的buffer.size来进行优化

## hdfs-site.xml
hdfs配置文件，可以通过调整里面的block.size来进行优化

## mapred-site.xml
MapReduce配置文件

# Hadoop的两个核心
## HDFS
### 操作HDFS文件的命令
- hadoop dfs
- hadoop fs
- hdfs dfs

### HDFS采用的模型
【主从结构master/slave】
- 主节点(master)
    - NameNode
    - JobTracker是运行在主节点上的重要进程
- 从节点(slave)
    - DataNode
    - TaskTracker是运行在从节点上的服务
### HDFS的命名空间
#### 文件
#### 块 
- hadoop1.0上的块的大小是64MB，hadoop2.0上的块的大小是128MB
- MapReduce上的Map一次只能处理一个块
- hdfs块默认是保存**3**份
- 好处
    - 支持大规模文件存储
    - 简化系统设计
    - 适合数据备份
#### 目录
### 正常的hadoop集群工作都会启动哪些进程
- NameNode
- DataNode
- Secondary NameNode

### 数据节点 vs. 名称节点
#### 数据节点
- 一个HDFS集群中可以有多个数据节点
- 用来存储具体的文件内容，每个数据块(block)可以在多个数据节点上存储多个副本
- 数据节点的数据被保存在**磁盘**中

#### 名称节点
- 一个HDFS集群中只有唯一一个名称节点
- 负责对**命名空间**进行管理，也就是维护整个hdfs文件系统的目录树，以及每个文件所对应的数据块所在位置信息(元信息)【注意这里存储的信息并不是**持久化**了】
- 保存了两个核心数据结构
    - fsImage：用于**维护**文件系统树以及文件树中所有文件和文件夹的**元数据**
    - editLog：操作日志文件，记录所有针对文件的创建、删除、重命名等操作
#### 只有一个名称节点带来的局限性
- 集群的可用性
- 性能的瓶颈
- 隔离的问题
- 命名空间的限制
### 第二名称节点
#### 【镜像备份】
相当于一个备用的NameNode，但不是NameNode的“热备份”。只是保存了名称节点的元数据信息。因此当名称节点发生故障/死机的时候，可以将第二名称节点的数据备份到NameNode上面。
#### 【定期合并】
可以有效解决editLog逐渐变大带来的问题。因为它可以通过定期合并editLog和fsImage，从而减小editLog文件大小，从而缩短名称节点重启时间。
#### 具体执行过程
主要负责对名称节点元数据的合并，当满足一定条件下，它会每隔一个小时主动对名称节点的editLog和fsImage进行合并。合并的时候会通知名称节点，这时候名称节点会停止正在对editLog进行的追加操作，同时会新建一个新的editLog，保证名称节点正常工作。接下来，第二名称节点会把名称节点本地的fsImage文件和editLog文件拉去到第二名称节点本地。并在内存中将两者进行合并最后产生最新的fsImage，把这个fsImage再发送给名称节点本地。

### hdfs的读写过程
注意在数据传送过程中均以Packet为单位
#### 写过程
1. 客户端与名称节点建立通信，请求上传文件。名称节点检查文件，看看父目录是否存在，并将feedback返回给客户端

2. 客户端向名称节点请求第一个block上传到哪几个DataNode服务器。名称节点查询所有从节点，然后返回对应的DataNode服务器给客户端(A,B,C)【名称节点和数据节点之间通过**数据节点协议**进行交互】

3. 客户端通过FSDataOutputStream模块请求A(就近原则)上传数据，然后等A收到请求后会继续吊用B，再B调用C，接着将这个通信管道建立完成。然后在A,B,C逐级应答客户端（这里其实使用的是RPC机制）

4. 客户端开始往A上传第一个Block，然后A收到后就会传给B， B传给C。

5. 当一个Block传送完成后，客户端再次请求NameNode上传第二个， 重复step 2-4

#### 读过程
1. 客户端通过DFS向名称节点请求下载文件；名称节点通过查询元数据，找到文件块所在的DataNode地址。
2. 客户端按照就近原则选择一台DataNode服务器请求读取数据，DataNode开始传输数据给客户端
3. 客户端先将数据存在本地缓存然后写入目标文件

### hdfs的局限性
- 不适合低延迟数据访问
- 无效高效存储大量小文件
- 不支持多用户写入及任意修改文件

## MapReduce
### 采用的策略
分而治之
### Mapper
- 负责“分”，将输入的元素转为`<key,value>`形式。将复杂的任务分解为若干个“简单任务”来处理。

### Reducer
- 负责对map阶段的结果进行汇总。
### Mapper 和 Reducer之间经过了shuffle操作
分区、排序、合并
### 合并(Combine) vs. 归并(Merge)
对于两个键值对`<'a', 1>, <'a', 1>`
- 合并：`<'a', 2>`
- 归并：`<'a', <1,1>>`
