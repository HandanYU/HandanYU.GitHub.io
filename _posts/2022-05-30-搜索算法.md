---
layout: post
title: 搜索算法
summary: 本章主要介绍了AI problems中搜索问题的一些算法。
featured-img: machine learning
language: chinese 
category: AI
---

#  状态搜索 （State-based Search)

# 1. Satisficing Planning vs. Optimal Planning

- 两者几乎是对立面，没有重合部分
- 对于很多问题对于satisficing planner很简单，但要对于optimal planner来说很难

## 1.1 Satisficing Planning

所有能够被搜索到的结果都OK，（即使我们更希望更lowest cost）

## 1.2 Optimal Planning

必须是最短路径(lowest cost)

# 2. 基本状态模型(Basic State Model/Classical Planning)

## 2.1 目标

写出一个能够解决所有经典搜索问题的程序

## 2.2 参数定义

- 状态模型(State Model)：S(P)
- 有限(finite)离散型(discrete)的状态空间(state space)：S
- 已知的初始状态(initial state)：$s_0$, $s_0  \in  S$
  - 只可能是一个
- 目标状态(goal states)：$S_G$, $S_G \subseteq S$
  -  [==注意==：由于目标状态可以不止一个，因此一般用集合形式来表示]
- 某个状态s下可执行操作(actions applicable in s)：$A(s) \subseteq  A, s\in S$
- 确定性转移函数(deterministic transition function)：$s'=f(a, s)$ for $a\in A(s)$
- 正的行动代价(positive action costs)：c(a, s)
- 结果(solution)：一个可执行序列，将$s_0$映射到$S_G$

#### 2.2.1 用state model表示$$m\times m$$ Manhattan Grid

Consider a $$m\times m$$ manhattan grid, and a set of coordinates $$V$$ to visit in any order, and a set of inaccessible coordinates (walls) $$W$$. Using Strips, a state-space model can be represented as $$P=<S,s_0,S_G,A,T,C>$$ 

*    $S = \{ \langle x , y, V' \rangle \mid x, y \in \{0,\dots,m-1\} \, \land \, V' \subseteq V \}$

*    $s_0 = \langle (0,0),V \setminus \{(0,0)\} \rangle$ 

*    $S_G = \{ \langle (x,y),\{\} \rangle \mid x,y \in \{0,\dots,m-1\} \}$ 

*    $A(\langle x , y, V' \rangle) = \{ \left( dx , dy \right) \mid $

     *   $ dx, dy \in \{-1, 0, 1\} $
     *   $\land \ |dx| + |dy| = 1 $
     *   $\land \ x + dx, y + dy \in \{0,\dots,m-1\}$
     *   $(x+dx,y+dy) \notin W \ \} $

*    $T(\langle x , y, V' \rangle,\left(dx, dy\right)) = \langle x+dx , y+dy, V' \setminus \{(x+dx, y+dy)\} \rangle $

*    $c(a, s) = 1$

## 2.3 状态模型的求解(Path-finding in graphs)

搜索算法：利用「经典状态模型」与「有向图」之间的关系

### 2.3.1 有向图与状态模型的对等关系

- 有向图的结点node -> 状态模型中的状态s
- 有向图的边edge (s, s') -> 状态模型中具有相同cost的转移(transition)

# 3. 搜索算法的分类

## 3.1 盲目式搜索 (Blind Search) Vs 启发式搜索(Heuristic Search)

### 3.1.1 盲目式搜索 (Blind Search)

- 只使用基本的原始信息
- 优点：简单直接，不需要额外信息
- 缺点：计算量大，效率低
- **e.g.:**
- DFS: Stack : Last-in-First-out
- BFS: Queue: First-in-First-out
- Dijkstra(Uniform Cost Search): Priority Queue: First-in-First-out, also being sorted so that can get the smallest one each time
- ID(Iterative Deepening)

### 3.1.2 启发式(信息)搜索 (Heuristic/Informed Search)

- 额外使用启发式方程
- 当在**satisficing planning**中，有远超于Blind Search的出色表现
- 当在**optimal planning**中，效果和Blind Search差不多
- e.g.:
  - 系统搜索 (Systemetric Search)
    -  Greedy best-first search (Satisficing Planning)
    -  Weighted A* (Satisficing Planning)
    -  A* (Optimal Planning)
    -  IDA*
  - 局部搜索 (Local Search)
    - Hill Climbing
    - Enforced hill-climbing (Satisficing Planning)
    - Genetic algorithms

#### 启发式方程 (Heuristic Function)

#### 定义

- 令$h$表示启发式方程
- $h(s)$ 表示状态s的启发值(heuristic value / h-value)，评估从状态s到最近一个目标状态的距离值
- $h^*$表示optimal/perfect heuristic （可以理解为real following cost)
- $h^*(s)$表示从状态s到目标状态的optimal/perfect heuristic

- 一个好的启发式方程

  - 衡量启发的信息和计算开销 Heuristic performance is always a balance between how well it directs the search (informedness) and how long it takes to compute (computation overhead)

#### 性质

如果某个启发式方程满足以下一个条件，则称其为对应的启发式方程。

- 安全性 (Safe)
  - $h^*(s)=\infin$ if $\forall s\in S, h(s)=\infin$。即从状态s到任意目标状态不可达，则$h^*(s)=\infin$
  - AKA：If a solution exists from state s, then $h(s) < \infin$
  - not safe:  then it can assign $h(s)=\infin$ to all nodes $n$ that lead to a solution
- 目标察觉性 (Goal-aware)
  -  $\forall s\in S_G, h(s)=0$
- 可采纳性 (Admissible)
  - $\forall s \in S, h(s) \leq h^*(s)$. 因为$h(s)$表示的到**最近**一个目标状态的距离值
- 一致性 (Consistent)
  -  for all transition $s \stackrel{a}{\longrightarrow}s'$, $h(s)\leq h(s')+c(a)$
- 主导性 (Dominate)
  - 假设有两个heuristic functions **h1,h2**，$$\forall s\in S, h_1(s) > h_2(s)$$，则说$$h_1$$ dominates $$h_2$$


**如果 h 具有一致性和目标察觉性，那么 h 具有可采纳性。如果 h 具有可采纳性，那么 h 具有目标察觉性和安全性。除此以外，不存在任何其他关系。**

- Consistent + Goal-aware = Admissible
- Admissible ->  Goal-aware & Safe

#### Greedy Best-First Search

```python
# Step1: 初始化openList, closedList，分别存放待扩展结点和已扩展遍历的结点。
openList := a new priority queue ordered by ascending h(state(node))
openList.insert(start())

closedList := an empty set

# 判断openList是否为空，如果为空，则返回搜索失败，即目标状态不可达。否则从openList中取出优先级最高的
while not openList.empty():
  	node = open.pop() # 取出优先级最高的
    # 检验是否是已经被扩展过的结点 check duplicates
    if state(node) not in closedList:
      	closedList.add(node)
    # 判读是否是goal state
    if is-target(state(node)):
      	return 'success'
    # 扩展结点：遍历当前结点的后继结点
    for a, s_next in succ(state(node)):
      	# 检验是否是已经被扩展过的结点 check duplicates
      	if (s_next not in closedList) and (s_next not in openList):
      			node_next = (node, a, s_next)
        if h(state(node_next)) < inifite: # 预判从node_next出发，是否可达目标结点
          	openList.insert(node_next)
 return 'unsolvable'
      
    
```

##### evaluation function

h

##### Properties

- 可以简单的这样理解：对于一个棋盘格中，它总是尝试向离目标节点更近的方向探索，怎样才算离目标节点更近呢？在只能上下左右四方向移动的前提下，我们通过计算当前节点到目标节点的距离来进行判断。

- Completed. 当检测duplicates且启发式方程是safe的

- 不能保证是optimal的，但搜索速度很快

- 当启发式方程发生严格单调变化的时候也不会发生变化（Does not vary with monotonic changes）

- with duplicate detection

- 数据结构：优先队列(e.g., min heap)，**根据$h(state(node))$升序排列**

  - 当假设$\forall s\in S, h(s)=0$，由于此时所有结点的$h$都一致了没有大小顺序可言，因此对于openList的顺序，我们有以下几种假设

    - FIFO: 也就是假设按照“先进先出”原则，则Greedy Best-First Search会退化为BFS

    - LIFO：也就是假设按照“后进先出”原则，则Greedy Best-First Search会退化为DFS

    - 根据 $g$​的大小，则Greedy Best-First Search会退化为Uniform-cost search((Dijkstra)

      

#### A*

```python
openList := a new priority queue ordered by ascending g(state(node)) +  h(state(node))
openList.insert(start())

closedList := an empty set
best_g_mapping := a dict mapping states to g-values

# 判断openList是否为空，如果为空，则返回搜索失败，即目标状态不可达。否则从openList中取出优先级最高的
while not openList.empty():
  	node = openList.pop()
    # 判断node是否已在closedList
    if state(node) not in closedList:
       # 判断 node 是否已在openList，如果不在如果在openList需要考虑是否re-open
        if state(node) not in openList or g(state(node)) < best_g_dict(state(node)):
            closedList.add(state(node))
            best_g_dict(state(node)) = g(state(node))
         if is-target(state(node)):
          	return 'success'
         for a, s_next in succ(state(node)):
          	node_next = (node, a, s_next)
            if h(state(node_next)) < infty:
              	openList.insert(node_next)
        
return 'unsolvable'
```

##### 相关术语

- Evaluation function: $f(s) = g(s) + h(s)$
  - g(s): 从起点到s经过的代价 previous/historical costs
  - h(s)：从s到最近一个目标状态的代价 feature costs
  - f-value越小，在优先队列中的优先权越大
  - openList按照f-value升序排列
  - if h(s) === 0, -> Uniform-cost search  （e.g. Dijsktra)
- 生成结点 (Generated Nodes)：Nodes inserted into **openList** ，即由当前结点扩展生成的后继结点
- 扩展结点 (Expanded Nodes)：Nodes pop from **openList**，即从openList中pop出来的优先级最高的结点（用于生成Generated Nodes的结点)
- 重扩展结点 (Re-expanded Nodes)/重开放结点 (Re-open Nodes)：扩展那些$s\in$closedList的结点

#####  Evaluation function

$f(s) = g(s) + h(s)$

##### 性质

- 对于具备安全性(safe)的h： Completed。【因为当h不具备安全性，也就是我们可以假设$\forall s \in S, h(s)=\infin$。这样就导致我们在一开始就终止了search，从而无法找到solution】

- 对于具备可采纳性(admissible)的h：Optimal。【因为当h不具备可采纳性，也就是我们可以假设$\exist s\in S, h(s) > h^*(s)$，这样就会使得我们错过在optimal path上的node，而选择了其他的path. 】

- 对于具备可采纳性(admissible)和一致性(Consistent)的h： A*不需要进行re-open能Optimal

- 当h是admissible但inconsistent的时候, A*不一定optimal

#### WA*

```python
openList := a new priority queue ordered by ascending g(state(node)) + W * h(state(node))
openList.insert(start())

closedList := an empty set
best_g_dict := {}

while not openList.empty():
  	node = openList.pop()
    if state(node) not in closedList or g(start(node)) < best_g_dict(state(node)):
      	closedList.add(state(node))
        best_g_dict(state(node)) = g(state(node))
        if is-target(state(node)):
          	return 'success'
        for a, s_next in succ(state(node)):
          	node_next = (node, a, s_next)
            if h(state(node_next)) < infty:
              	openList.insert(node_next)
return 'unsolvable'
```

##### Evaluation  function 

g + w*h

- Parameter: the weight **W** 
  - W = 0: 一致代价搜索(Dijkstra)
  - W=1:  WA* -> A*
  - W=$\infin$：WA* -> Greedy Best-First Search 【因为此时g的值对evaluation function来说影响不大，因此就只留下h，退回到了GBFS】

##### 性质

- 当**W > 1**， WA*是有界次优的(bounded suboptimal)。因为当h是可采纳性的(admissible)，于是返回结果不会超过最优解的W倍

### 3.1.3 GBFS vs. A\*. vs. WA*

|                     | GBFS                                            | A*                         | W*          |
| ------------------- | ----------------------------------------------- | -------------------------- | ----------- |
| Estimation Function | h(s)                                            | g(s)+h(s)                  | g(s)+w*h(s) |
| Optimal             | No                                              | No (unless **Admissible**) | No          |
| Complete            | No (unless **duplication check** and **safe** ) | No (unless **Safe**)       |             |

## 3.2 系统搜索 (Systematic Search) Vs 局部搜索 (Local Search)

- 两者存在**交集**
- 两者都适用于**satisficing planning**
- 但在**optimal planning**中更适合使用**Systematic Search**

### 3.2.1 系统搜索 (Systematic Search)

- 同时考虑大量的搜索结点
- 在**optimal planning**中更偏向于使用

### 3.2.2 局部搜索 (Local Search)

- 一次只考虑一个（或几个）候选搜索结点

#### Hill Climbing

##### 算法流程

![i3](/assets/img/post_img/33.png)

假设我们从$I$出发，目标结点为$G$

- 遍历$I$的所有子结点，$A,B,C$，它们的$h$分别为8, 7, 5，因此发现C的$h$最小，于是我们丢弃$A, B$的分支选择下一步到结点C。此时path: $I\rightarrow C$
- 从$C$出发，遍历它的所有子结点，$D, E$，它们的$h$分别为3, 5，因此发现$D$的$h$最小，于是我们丢弃$E$的分支选择下一步到结点$D$。此时path:$I\rightarrow C\rightarrow D$
- 从$D$出发，遍历它的所有子结点，$F, H$，它们的$h$分别为1, 2，因此发现$F$的$h$最小，于是我们丢弃$H$的分支选择下一步到结点$F$。此时path:$I\rightarrow C\rightarrow D\rightarrow F$
- 从$F$出发，遍历它的所有子结点$G$，此时找到目标结点，则停止搜索。path:$I\rightarrow C\rightarrow D\rightarrow F\rightarrow G$

```python
node = start()
forever:
  if is-target(state(node)):
    return 'success'
  L = {(node, a, next_state)|(a, next_state) in succ(state(node))}
  node = an element of L minimizing h 
  break only when h reaches at minimum value or early stopping
```

##### 性质

- 该算法仅在满足$\forall s \notin S_G ,h(s)>0$下才有意义：【因为当非目标结点s'的h为0的时候，当遍历到s'的时候得到的h已经达到最小了，此时算法会停止，因此再也无法找到真正的目标结点】
- Imcompleted and unoptimal
- 类似gradient decline，容易陷入local optimal。
  - 为避免其陷入局部最优：平局决胜制（tie-breaking strategies）、重启（restarts）、…
- 一般在AI Planning中不会使用Hill Climbing

#### Enforced Hill Climbing

##### 算法流程

结合BFS进行遍历，expand一层后，比较该层结点的h与current optimal h的值

- 如果$h(node_c) < $current optimal $h$   【注意：这边有个randomly tie breaking，只要找到一个比current optimal h小的就执行以下操作，不需要去选择最小的】

- 丢弃除了node c以外的所有结点及其分支，仅仅保留通到node c的path，并从node c开始继续按照之前的方法遍历比较

- 如果没有结点的$h$ <current optimal $h$
  - 则继续按照上述方法再expand一层开始遍历比较

![i4](/assets/img/post_img/34.png)

- 假设从$I$开始

    - 从$I$开始，此时的最佳$h$为7。展开$I$的所有子结点，$A, B, C$，结点C的$h$=5。因为5 < 7，因此丢弃$A, B$结点及它们的path分支，选择从C开始，并将此时的最佳$h$赋值为5。此时path: $I\rightarrow C$, 最佳$h=5$

    - 从$C$开始，展开$C$的所有子结点，$D, E$，结点D的$h=5$，因为5 == 5，因此此时无法选择从哪个结点开始。

    - 展开所有$D,E$的所有子结点，$F, H, J, K$，结点J的$h=5$，因为5 == 5，因此此时又无法选择从哪个结点开始。

    - 展开所有$F, H, J, K$的所有子结点，$L, M, N$，结点N的$h=4$，因为4 < 5，因此丢弃所有其他结点的path分支，接下来从N开始。此时path: $I\rightarrow C \rightarrow D \rightarrow H \rightarrow N$

##### Properties

- 和Hill Climbing一样也需要满足$\forall s \notin S_G ,h(s)>0$下才有意义
- 一部分用到Systematic Search（通过BFS进行expand），一部分用到Local Search（利用Hill Climbing丢弃一部分分支而选择其中一个）

# 4 搜索算法中的术语(Search Terminology)

## 4.1 搜索结点 (Search node **n**)

包含搜索过程中的一个搜索状态(s) + 如何到达该状态的information

## 4.2 **Search state** vs. Search node

 search node = search state + info

- information 一般包括
  - state($\sigma$)：
  - parent($\sigma$)：指向父结点
  - action($\sigma$)：从state(parent($\sigma$))到state($\sigma$)的action
  - g($\sigma$)：从根结点到结点$\sigma$的总cost
  - 对于根结点，无所谓parent($\sigma$)和action($\sigma$)

## 4.3 路径代价

(Path cost **g(n)**)到达结点n的cost

## 4.4 最优代价 (Optimal cost **g***)

最优结果路径的cost，g*(s)表示到达状态s的最便宜路径的cost

## 4.5 结点扩展 (Node expansion)

通过运用所有该结点状态的可执行action来生成当前结点n的所有后继结点(successors)。$a\in A(s)$

## 4.6 搜索策略 (Search Strategy)

决定扩展哪个结点的方法

## 4.7 Open list

存放所有待扩展的结点集合

## 4.8 Closed list / explored set

存放所有已经扩展过的**搜索状态**的集合。只适用于==图搜索(Graph Search)==。

## 4.9 搜索空间 (Search Space)

经典搜索空间包括以下操作

- start()：生成初始搜索状态
- is-target(s)：检验搜索状态s是否是一个目标状态
- succ(s)：生成搜索状态s的后继状态及所采取的行动(a, s')。

# 5.World States vs. Search States

#### 前进 (Progression) 规划

- Search states = World States
- 从问题的初始状态出发，考虑行动序列，直到找到一个能够得到目标状态的序列。

#### 后退 (Regression) 规划

- (一般不考虑)

- Search states = Set of World States
- 从目标状态开始，向后应用行动，直到找到一个能够达到初始状态的行动序列。

# 6. 评估搜索策略的指标(Evaluation)

## 6.1 Guarantees

#### 完整性（Completeness）

对于一个有解问题，该搜索策略总能找到一个结果 (Guarantee to find a solution when there is one)

#### 最优性 （Optimality）

返回值是最优解

## 6.2 Complexity

- 状态空间的特征
  - 分支因子 (Branching factor) **b**：每个结点的后继结点个数
  - 目标深度 (Goal depth) **d**：到达最浅的目标状态所需行动的数量

#### 时间复杂度

#### 空间复杂度

# 7. DFS vs. BFS vs. IDS

- d: goal state所在layer，D: early stop layer搜索的最大深度
- DFS, because of loop and infinity in one direction -> imcomplete. 假设最大深度为D
- 对于IDS，d=D.
- 其中IDS有时候time complexity > BFS's
  - 对于iDS, time complexity = $d\times b + (d-1)\times b^2+(d-2)\times b^3+\dots +1\times b^d$
  - 也就是若假设goal state在第d层，则对于第一层需要被遍历到d次，第二层需要被遍历d-1次，最后一层需要被遍历1次。虽然在数量级上与BFS一致，但假设d = 5, b = 10.则有
  - 也就是IDS比较适合于大状态空间且未知深度


|      | Completness | Optimality                                        | Time Complexity | Space Complexity |
| ---- | ----------- | ------------------------------------------------- | --------------- | ---------------- |
| BFS  | Yes         | Conditional Optimal (only when costs are uniform) | O($b^d$)        | O($b^d$)         |
| DFS  | No          | No                                                | O($b^D$)        | O(bD)            |
| IDS  | Yes         | Conditional Optimal(only when costs are uniform)  | O($b^d$)        | O(bd)            |

- BFS is complete：由于是breath first， 因此即使BFS深度无穷，但总能找到goal state。因此BFS是Completness的
- BFS is conditional optimal：
  - 当cost是uniform的时候，也就是所有path的cost都相等的时候，只要通过最短路径的方法找到的就是optimal的。
  - 但当cost不相等的时候，如果我们选择了一个direction，虽然很早的能找到goal state，但实际存在另一条cheaper costs path. （除非我们expand node with the lowest accumulated cost)
  - example: 如下图，当我们选择left first，此时会直接找到goal state但此时的cost=1000，很显然不是optimal的
![image-3](/assets/img/post_img/35.png)

- DFS is imcomplete
  - 当我们选择的一个branch中存在一个loop，goal state在下一个branch中，此时如果在不设置duplicated机制的情况下，采用DFS会在这个loop无限的查找，因此无法找到goal state
  - 当我们选择的一个branch的深度是无限的，goal state在下一个branch中，此时如果在不设置early stop depth的情况下，采用DFS会在这个branch中无限向下查找，因此也无法找到goal state
- DFS is unoptimal：由于它是imcomplete因此也就是unoptimal了

### node-generation time vs. node-expansion time

- 对于BFS来说，若在从队列中pop出state后判断该state是否是goal state，此时计算得到的时间称为node-generation time。若在从队列中pop出state并将该state的child-state push到队列后再该state是否是goal state，此时计算得到的时间称为node-expansion time。因此当goal state在一层中的最右边的结点出现，则采用node-expansion time的复杂度是$O(b^{d+1})$比node-generation time多出一层的时间