---
layout: post
title: 机器学习常见考点
summary: 本章主要总结了面试中涉及到的机器学习相关的一些问题。
featured-img: machine learning
language: chinese 
category: machine learning
---


# 各类激活函数的比较

![image-20200603124717993](/assets/img/post_img/6.png)

取值范围：(0,1),(-1,1),[0,inf]

能根据输出的值判断使用的激活函数

对数几率回归（logistics regression）和一般回归分析有什么区别？：
A. 对数几率回归是设计用来预测事件可能性的
B. 对数几率回归可以用来度量模型拟合程度
C. 对数几率回归可以用来估计回归系数
D. 以上所有
答案：D

<a name="召回率、准确率、精确率"/>

# 召回率、准确率、精确率

![img7](/assets/img/post_img/7.png)

<a name="准确率(Accuracy)"/>

## 准确率(Accuracy)

准确率(accuracy) = 预测对的/所有 = (TP+TN)/(TP+FN+FP+TN)

缺点：结果偏向样本数量大的样本，不适用于糖尿病等疾病的监测（由于正常人占比远远大于患糖尿病等疾病的人，因此当模型的准确率很高的时候，并不能相信该模型是优秀的，因为这高准确率主要由TN来决定来，但在这种情况下，我们更关注TP尽可能大）

<a name="精确率(Precision)"/>

## 精确率(Precision)

精确率(precision) = TP/(TP+FP)

缺点：只关心正样本的准确率

<a name="召回率(Recall)"/>

## 召回率(Recall)

召回率(recall) = TP/(TP+FN)

适用于“犯罪监测”，此时关心被误判数量仅可能小，也就是FN尽可能小，TP尽可能大


假设我们要解决一个二类分类问题, 我们已经建立好了模型, 输出是0或1, 初始时设阈值为0.5, 超过0.5概率估计, 就判别为1, 否则就判别为0 ; 如果我们现在用另一个大于0.5的阈值, 那么现在关于模型说法, 正确的是 :
A. 模型分类的召回率会降低或不变
B. 模型分类的召回率会升高
C. 模型分类准确率会升高或不变
D. 模型分类准确率会降低
答案: AC

the true positive rate will stay the same if we keep increasing the cutoff from 0.5 to 0.75, since the all real positive samples can still be predicted to the positive samples, and the true positive rate only rely on the number of real positive sample.

<a name="训练误差和测试误差"/>

# 训练误差和测试误差

随着训练样本的增多，平均训练误差会逐渐增大，平均测试误差会逐渐减小。由于训练数据增多，使得原先拟合模型效果变差，因此训练误差变差，但随着训练数据的增多，最终使得整体拟合效果更好，则测试误差会越小，因此训练误差和测试误差之间的差距就会减小。

![image8](/assets/img/post_img/8.png)

<a name="过拟合和欠拟合"/>

# 过拟合和欠拟合

## 过拟合

- 在训练集上的表现好，但在测试集上的表现能力差。
- 模型偏差为0，方差大
- 泛化能力差

## 欠拟合

- 对训练样本的一般性质尚未学好
- 模型偏差大，方差为0

<a name="产生过拟合的原因"/>

## 产生过拟合的原因

1. 模型过于复杂
   - 特征过多
   - 神经元过多
   - 核函数选择的过于复杂
2. 训练数据量太少

<a name="产生欠拟合的原因"/>

## 产生欠拟合的原因

1. 模型过于简单
2. 训练数据量过多

<a name="过拟合的解决办法"/>

## 过拟合的解决办法

1. 增加数据量
2. 降低模型的复杂度
3. 添加正则化项
4. 如果有正则项，则适当增大正则化系数
5. 集成学习的方法
6. 特征降维
7. 交叉验证


<a name="欠拟合的解决办法"/>

## 欠拟合的解决办法

1. 添加新特征，如在决策树学习中扩展分支，在神经网络学习中增加训练次数
2. 增加模型的复杂度，尝试使用核SVM，DNN，决策树
3. 如果有正则项，减少正则化系数


<a name="用来划分样本的方法"/>

# 用来划分样本的方法

1. 随机设置比例
2. 交叉验证
3. 自助采样：适用于数据集较小，集成学习
4. 留出法

<a name="算法是否需要调参"/>

# 算法是否需要调参

## 需要进行调参的算法

1. 神经网络
2. SVM
3. 岭回归
4. LASSO
5. 加权线性回归
6. LR
7. K-Means
8. AdaBoost
9. GMM

## 不需要进行调参的算法

1. 决策树
2. LDA
3. NB
4. 线性回归


<a name="算法是否需要迭代"/>

# 算法是否需要迭代

## 需要经过多次迭代的算法

1. LR
2. 决策树
3. 神经网络
4. 聚类
5. AdaBoost
6. SVM

## 不需要经过多次迭代的算法

1. LDA
2. 线性回归
3. NB

<a name="算法是否需要归一化处理"/>

# 算法是否需要归一化处理

## 需要进行归一化的算法

### 需要进行梯度下降操作的算法

因为当不归一化的时候可能在梯度下降法寻求最优解时，收敛速度很慢迭代次数很多。

e.g.LR，SVM，AdaBoosting,神经网络

### 需要进行计算距离的算法

因为如果其中一个特征值域范围很大，那么在进行距离计算的时候就主要取决于这一个特征而忽视其他特征。

e.g.KNN，K-Means，LDA

## 不需要进行归一化的算法

### 树形结构的算法

由于树形结构寻找最优解的时候采用的不是梯度下降（因为树形结构模型是分段的一般不可导），而是通过寻找最优分裂点

e.g.决策树，随机森林，XGBoost,Boosting Tree，GBDT

### 概率模型

高斯混合模型(GMM)，朴素贝叶斯，LR

<a name="逻辑斯蒂回归和线性回归的区别"/>

# 逻辑斯蒂回归和线性回归的区别

①逻辑斯蒂回归解决的是分类问题，而线性回归解决的则是回归问题。逻辑斯蒂回归将实例x划分到条件概率最大的那一类。
②逻辑斯蒂回归的因变量是离散的，而线性回归得因变量是连续的，逻辑斯蒂回归可以看成是对数几率的线性回归。
③逻辑斯蒂回归参数求解的过程中，使用到了极大似然估计而线性回归则使用最小二乘法。二者在求解时均用到了梯度下降的方法。


<a name="生成模型和判别模型"/>

# 生成模型和判别模型

1. 生成式模型估计它们的联合概率分布P(x,y)
2. 判别式模型估计决策函数F(X)或后验概率分布P(y|x)

## 生成模型

1. GMM

2. 朴素贝叶斯

3. HMM（隐马尔可夫模型）

   

## 判别模型

1. SVM
2. LDA
3. 神经网络
4. 线性回归
5. 逻辑回归
6. 决策树
7. Boosting

<a name="参数模型和非参数模型"/>

# 参数模型和非参数模型

## 参数模型
- 模型参数独立于数据
- 简单，容易理解，训练快，不需要大量数据进行训练
- 限定了模型的结构和复杂度，可能欠拟合

1. 逻辑回归
2. 线性成分分析
3. 感知机
4. 线性判别分析（LDA）
5. 朴素贝叶斯
6. K-Means

## 非参数模型
- 参数取决于数据
- 灵活，强大
- 训练慢，容易过拟合，需要足够数据去训练

1. 决策树
2. KNN
3. 支持向量机
4. 神经网络

<a name="线性分类器和非线性分类器"/>

# 线性分类器和非线性分类器

## 线性分类器

LR,贝叶斯分类，单层感知机，线性回归，SVM（线性核）,LDA，朴素贝叶斯，

## 非线性分类器

决策树、多层感知机（神经网络），KNN，SVM（非线性核）

## 根据特征数量与样本数量比选择分类器

1. 当特征数量很大且与样本数量差不多，选择LR或SVM(线性核)
2. 当特征数量较小，样本数量一般时，选择SVM(非线性核）
3. 当特征数量较小而样本数量很多，选择添加特征变为第一种


<a name="解决类别不平衡问题"/>

# 解决类别不平衡问题

1. 直接对训练集中占多数的类别样本进行“欠采样”
2. 对训练集中占少数的类别样本进行“过采样”（如通过对该类数据进行插值），也就是复制多个该类别样本
3. 阈值移动
4. 直接基于原数据集进行学习，对预测值进行再缩放处理
5. 代价敏感学习
6. 集成学习


<a name="异常点敏感度"/>

# 异常点敏感度

## 异常值敏感的算法

线性回归，LR,AdaBoosting，SVM

## 异常值不敏感的算法

<a name="各算法对应的损失函数"/>

# 各算法对应的损失函数

1. 最小二乘法——均方误差
2. SVM——Hinge Loss
3. LR——对数损失
4. AdaBoosting——指数损失函数

<a name='梯度爆炸 & 梯度消失'/>

# 梯度爆炸 & 梯度消失
## 梯度爆炸

神经网络中的权重初始值很大的时候，从输出层到输入层每一层都会✖️权重，经过多层后该大权重被多次相乘，于是计算得到的梯度就会很大，也就是所谓的梯度爆炸。

- 容易出现在循环神经网络

### 解决方法

- 使用非饱和的激活函数: e.g., ReLU
- 批量规范化（Batch Normalization）
- 更快的优化器
- LSTM
- 梯度截断（Gradient Clipping）

## 梯度消失

- 当使用Sigmoid激活函数的时候，梯度消失容易出现在网络进行反向传播的时候
由于Sigmoid函数的导数范围在(0, 0.25]之间，因此当网络层数很多的时候，在反向传播的时候多个在(0, 0.25]之间的小数相乘，得到的结果会十分的小甚至接近于0，因而参数无法有效更新，从而说梯度消失。

### 解决方法
- 使用非饱和的激活函数: e.g., ReLU
- LSTM

# 神经元死亡
在使用ReLU作为激活函数的时候，由于ReLU会ignore负数。对于bias来说，更新几次后很可能变为一个很小的负数，这时候经过ReLU激活后，bias无法被更新。


<a name='使用LeakyReLU来替换ReLU'/>

# 使用LeakyReLU来替换ReLU
LeakyReLU通过对于输入值为负数部分改为$$f(x)=\alpha x$$，来可以解决[「神经元死亡问题」](#神经元死亡)

<a name='从RNN到LSTM再到GRU'/>

# 从RNN到LSTM再到GRU

## RNN

![img26](/assets/img/post_img/26.png)

$$h_t = \tanh(w_{ih}x_t+b_{ih}+w_{hh}h_{t-1}+b_{hh})$$

$$o_t = g(w_oh_t+b_o)$$

一般输入数据$$x$$的维度通常是[batch_size$$\times$$seq_len$$\times$$input_size]，这边需要注意一下**seq_len**。在进行RNN前向过程中，需要进行**seq_len**次，用以上公式保留记录上一次的隐藏信息。

我们可以这样理解，在做文本生成的时候，将每句话看作一个样本序列数据，则该句话的字符数（句子长度）为**seq_len**，每个字符进行word embedding后的维数embed_dim就是**input_size**。然后假设目前我们拿到了N条数据，这里N就是**batch_size**。

但这里存在一个细节问题，在进行batch数据组装的时候由于每句话的长度都是不等的，但对于输入数据集来说，这N条数据组成的特征矩阵必须是一个方方正正的tensor，也就是每个句子必须等长，于是我们可以将这N条数据分别padding到最大句子长度。但同时要记得在进入RNN模型的时候需要将padded后的数据集还原到原始长度。


运用PyTorch实现RNN，详见我的[「另一篇」](https://handanyu.github.io/deep%20learning/2022/01/04/build-network-pytorch.html)

### 存在问题
- 梯度消失和梯度爆炸

由于前面阶段的隐藏信息一直会被保留影响后面的数据预测，则在反向传播的过程中对于很后面时刻的损失函数进行求偏导的时候，若假设权重也是(0,1)之间的小数的时候，对于过去已久的隐藏数据状态会有大量小数连乘，从而导致梯度消失。也就很难让较早时刻的信息传递到后面时刻的数据。同时如果权重特别大，则会有大量的大数相乘，从而导致梯度爆炸。因此归根结底，是由于导数连乘的原因。

## LSTM
![img27](/assets/img/post_img/27.png)
为了RNN存在长期依赖问题导致的梯度消失梯度爆炸问题，LSTM引入细胞状态和三个门的概念，来使得部分连乘项为0或1。（主要用Sigmoid激活函数来更新或遗忘）

LSTM中增加了细胞状态（与RNN中的隐藏状态类似）用于保存历史状态信息，同时保留了RNN中隐藏状态概念，但在LSTM用于保存上一时刻的输出信息。

新增三个门的概念
- 遗忘门 （用于遗忘丢弃部分历史状态）
   - 输入$$h_{t-1}$$和$$x_t$$ 
   - 用Sigmoid进行激活，得到一个数组，每个数都在[0,1]范围内
   - 与细胞状态进行按位相乘，用于遗忘丢弃一些隐藏状态值小的。
- 输入门 （用于增加部分历史状态）
   - 输入$$h_{t-1}$$和$$x_t$$ 
   - 用tanh激活后得到新的输入信息，但这所有产生的信息不都需要加入到细胞状态中
   - 用Sigmoid进行激活，和遗忘门中作用一样，与用tanh激活产生的新信息进行按位相乘，剔除一些信息，保留部分信息加入细胞状态
- 输出门 （用于判断输出部分信息到当前状态）
   - 细胞状态经过tanh函数激活得到可以输出的信息
   - 对于输入的输入$$h_{t-1}$$和$$x_t$$，用Sigmoid激活来判断哪些位置的数据需要丢弃。
   - 最终按位相乘，丢弃不需要的数据后输出当前状态

```python
def LSTM(prev_ct, prev_ht, input):
   combine = combine(prev_ht, input) # 线性组合
   # forget gate
   ft = Sigmoid(combine) 
   # input gate
   candidate = tanh(combine)
   it = Sigmoid(combine)
   ct = ft * prev_ct + it * candidate 
   # output gate
   ot = Sigmoid(combine)
   ht = ot * tanh(ct)
   return ht, ct
```
## GRU
![img28](/assets/img/post_img/28.png)
这里只用到隐藏状态，且只有两个门（重置门和更新门）
- 重置门
运用Sigmoid激活函数判断哪些隐藏信息可以丢弃
- 更新门
相当于LSTM中的遗忘门和输入门，运用tanh激活产生新的信息，运用Sigmoid判断最终可添加那些新信息

**优点**
训练速度会比LSTM快一些。


# Batchsize的大小会有什么影响
- Batchsize大，训练时间短，但消耗内存大
- 当batchsize很小的时候，会导致训练时间很长，不容易收敛。

# 协方差和相关性有什么区别
- 当变量的量纲不同的时候，协方差值不能反映两者之间的关系，而是需要用相关性将两者的量纲都控制在-1，1之间。

# 策略方法
## 经验风险 （经验损失）
- 模型关于训练集的平均损失
- 根据大数定理，当样本容量$$n$$趋于无穷的时候，经验风险就趋近于期望风险，因此也就说可以用经验风险去估计期望风险。但在实际情况下，由于样本容量有限。

### 经验风险最小化
- 当样本量足够大的时候，经验风险最小化策略可以保证有很好的学习效果
- e.g., 最大极大似然估计(MLE)

### 结构风险最小化
- 当样本容量很小时，经验风险最小化的学习效果并不是很好，会产生过拟合。
- 结构风险最小化就是为了防止过拟合提出的策略
- e.g., 正则化(Regularization)

### Trade off 经验风险最小化 & 结构风险最小化
- 结构风险小需要经验风险与模型复杂度同时小；
- 结构风险小的模型一般对训练数据和未知的测试数据都有较好的预测效果
- 监督学习问题就是经验风险函数或结构风险函数的最优化问题

## 策略方法总结
- 梯度下降法 —— 代价风险最小化
- 正则化 —— 结构风险最小化
- 最大极大似然估计(MLE) —— 经验风险最小化
- 朴素贝叶斯 —— 期望风险最小化（后验概率最大化）